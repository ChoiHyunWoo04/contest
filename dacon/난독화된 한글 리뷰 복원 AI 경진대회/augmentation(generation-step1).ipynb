{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a6194e-4285-47b8-8d05-a95007b4cfc4",
   "metadata": {},
   "source": [
    "## train.csv의 output을 훈련 데이터로 사용한 파인 튜닝 모델을 통해 리뷰 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263bf8d5-887e-40d7-9c09-d6a64b252bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f6b8c1-1384-4fc7-9b47-2e150f7a42c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97c1d8d075e4bc8820c675b88db629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"beomi/gemma-ko-7b\"\n",
    "FINETUNE_MODEL = \"./gemma-ko-7b-finetuning-generate-reviews\"\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9517a855-256e-47c3-aa36-2cfb32076d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe_finetuned = pipeline(task=\"text-generation\", model=finetune_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a1fbbe-f282-4265-b62a-f9c79b6cbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incomplete_sentence(text):\n",
    "    # 마지막 마침표(.) 또는 느낌표(!)의 위치 찾기\n",
    "    last_period_index = text.rfind('.')\n",
    "    last_exclamation_index = text.rfind('!')\n",
    "    \n",
    "    # 두 개 중 더 뒤에 있는 위치 찾기\n",
    "    last_index = max(last_period_index, last_exclamation_index)\n",
    "\n",
    "    if last_index != -1:\n",
    "        return text[:last_index + 1]\n",
    "    else:\n",
    "        # 마침표(.)나 느낌표(!)가 없으면 None 반환\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec85f029-bbc4-48ce-9863-d2ec28e72216",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_reviews = []\n",
    "\n",
    "prompt = r\"\"\"<bos><start_of_turn>user\n",
    "이 숙박시설에 대한 솔직한 리뷰를 작성해 주세요:\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "\n",
    "prompts = [prompt] * 100  # 프롬프트 n개를 리스트로 생성\n",
    "\n",
    "# 병렬 처리\n",
    "generated = pipe_finetuned( \n",
    "    prompts,\n",
    "    num_return_sequences=1,\n",
    "    temperature=1.0,\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    batch_size=8  # 병렬 처리 크기\n",
    ")\n",
    "\n",
    "# 모든 생성된 텍스트 처리\n",
    "for gen in generated:\n",
    "    generated_text = gen[0]['generated_text']\n",
    "    result = generated_text[len(prompt):].strip()\n",
    "    result = remove_incomplete_sentence(result)  # 문장 정리\n",
    "\n",
    "    if result is not None:\n",
    "        # <end_of_turn> 기준으로 모델 응답만 추출\n",
    "        result = result.split('<end_of_turn>\\n<start_of_turn>model\\n')\n",
    "        restored_reviews.extend(result)  # 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3ba3d3-7c49-4f65-833d-a18febbb941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'input': [\"\" for _ in range(len(restored_reviews))],\n",
    "                   'output': restored_reviews})\n",
    "\n",
    "df.to_csv('./data/generated_reviews.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dc6da-5e8c-4bb4-908d-f3692b5e317f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
